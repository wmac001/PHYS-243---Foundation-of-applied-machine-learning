{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " array([5, 0, 4, ..., 4, 5, 6], dtype=int8))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#initialize\n",
    "\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "from scipy import stats\n",
    "# import the necessary packages\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Downloading the dataset\n",
    "try:\n",
    "    from sklearn.datasets import fetch_openml\n",
    "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
    "    mnist.target = mnist.target.astype(np.int8) \n",
    "except ImportError:\n",
    "    from sklearn.datasets import fetch_mldata\n",
    "    mnist = fetch_mldata('MNIST original')\n",
    "mnist[\"data\"], mnist[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 75 / 25 Train-Test Split\n",
    "(train_data, test_data, train_labels, test_labels) = train_test_split(mnist[\"data\"][:5000], mnist[\"target\"][:5000], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Allocation ---------------------\n",
      "training: 3600\n",
      "validation: 400\n",
      "testing: 1000\n"
     ]
    }
   ],
   "source": [
    "# 90 / 10 Train / Validation Split\n",
    "(train_data, validation_data, train_labels, validation_labels) = train_test_split(train_data, train_labels,\n",
    "test_size=0.1, random_state=84)\n",
    "\n",
    "#SPLIT ALLOCATION\n",
    "print(\"Split Allocation ---------------------\")\n",
    "print(\"training: {}\".format(len(train_labels)))\n",
    "print(\"validation: {}\".format(len(validation_labels)))\n",
    "print(\"testing: {}\".format(len(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding 9's using K- Nearest Neighbor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, accuracy=95.00%\n",
      "k=2, accuracy=94.50%\n",
      "k=3, accuracy=93.75%\n",
      "k=1 achieved highest accuracy of 95.00% on validation data\n"
     ]
    }
   ],
   "source": [
    "# initialize the values of k\n",
    "# list of accuracies for each value of k\n",
    "k_val = range(1, 30)\n",
    "accuracies = []\n",
    " \n",
    "# loop over various values of k\n",
    "for k in range(1, 4):\n",
    "# train the k-Nearest Neighbor classifier with k\n",
    "    model = KNeighborsClassifier(n_neighbors=k)\n",
    "    model.fit(train_data, train_labels)\n",
    " \n",
    "# evaluation of model\n",
    "    score = model.score(validation_data, validation_labels)\n",
    "    print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    accuracies.append(score)\n",
    " \n",
    "# highest accuracy\n",
    "i = int(np.argmax(accuracies))\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (k_val[i],\n",
    "accuracies[i] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "model = KNeighborsClassifier(n_neighbors=k_val[i])\n",
    "model.fit(train_data, train_labels)\n",
    "k_nearest_predictions = model.predict(test_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K Nearest Score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        94\n",
      "           1       0.90      0.98      0.94       114\n",
      "           2       0.98      0.88      0.93       111\n",
      "           3       0.91      0.93      0.92       100\n",
      "           4       0.94      0.91      0.93       115\n",
      "           5       0.95      0.90      0.92        87\n",
      "           6       0.92      0.96      0.94        83\n",
      "           7       0.93      0.92      0.93       106\n",
      "           8       0.95      0.88      0.92        86\n",
      "           9       0.87      0.90      0.89       104\n",
      "\n",
      "   micro avg       0.93      0.93      0.93      1000\n",
      "   macro avg       0.93      0.93      0.93      1000\n",
      "weighted avg       0.93      0.93      0.93      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report for each digit\n",
    "print(\"K Nearest Score\")\n",
    "print(classification_report(test_labels, k_nearest_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions: 93.96\n",
      "actual #: 104\n",
      "about 94.0 nines!\n"
     ]
    }
   ],
   "source": [
    "#how many 9's did I find\n",
    "est= np.round(sum(x == 9 for x in k_nearest_predictions)*.87,0)\n",
    "print(\"correct predictions: {}\".format(sum(x == 9 for x in k_nearest_predictions)*.87))\n",
    "print(\"actual #: {}\".format(sum(x == 9 for x in test_labels)))\n",
    "\n",
    "print(\"about \"+format(est)+\" nines!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding 9's Using Decision Tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the values of d\n",
    "# list of accuracies for each value of d\n",
    "max_i = []\n",
    "\n",
    "for i in range (0,20):\n",
    "    depth_val = range(1, 20)\n",
    "    tree_accuracies = []\n",
    "    # loop over various values of d\n",
    "    for k in range(1, 20):\n",
    "    # train the decision-tree classifier with depth\n",
    "        model = tree.DecisionTreeClassifier(max_depth=k)\n",
    "        model.fit(train_data, train_labels)\n",
    " \n",
    "    # evaluation of model\n",
    "        score = model.score(validation_data, validation_labels)\n",
    "        #print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "        tree_accuracies.append(score)\n",
    " \n",
    "    # highest accuracy\n",
    "    i = int(np.argmax(tree_accuracies))\n",
    "    #print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (depth_val[i],\n",
    "    #tree_accuracies[i] * 100))\n",
    "    max_i.append(i)\n",
    "depth = max(set(max_i), key=max_i.count)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data\n",
    "model = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "model.fit(train_data, train_labels)\n",
    "tree_predictions = model.predict(test_data)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Score\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.95      0.91        94\n",
      "           1       0.88      0.83      0.86       114\n",
      "           2       0.72      0.73      0.72       111\n",
      "           3       0.69      0.72      0.71       100\n",
      "           4       0.84      0.76      0.80       115\n",
      "           5       0.78      0.64      0.70        87\n",
      "           6       0.81      0.84      0.83        83\n",
      "           7       0.82      0.86      0.84       106\n",
      "           8       0.70      0.74      0.72        86\n",
      "           9       0.76      0.81      0.79       104\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1000\n",
      "   macro avg       0.79      0.79      0.79      1000\n",
      "weighted avg       0.79      0.79      0.79      1000\n",
      "\n",
      "Accuracy: 0.789\n"
     ]
    }
   ],
   "source": [
    "# classification report for each digit\n",
    "print(\"Decision Tree Score\")\n",
    "print(classification_report(test_labels, tree_predictions))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_labels, tree_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct predictions: 75.89999999999999\n",
      "actual #: 104\n",
      "about 76.0 nines!\n"
     ]
    }
   ],
   "source": [
    "#how many 9's did I find\n",
    "est_tree = np.round(sum(x == 9 for x in tree_predictions)*.69,0)\n",
    "print(\"correct predictions: {}\".format(sum(x == 9 for x in tree_predictions)*.69))\n",
    "print(\"actual #: {}\".format(sum(x == 9 for x in test_labels)))\n",
    "\n",
    "print(\"about \"+format(est_tree)+\" nines!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding 9's Using Random Forest\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=13 achieved highest accuracy of 95.50% on validation data\n"
     ]
    }
   ],
   "source": [
    "depth_val = range(1, 20)\n",
    "forest_accuracies = []\n",
    "    # loop over various values of d\n",
    "for k in range(1, 20):\n",
    "    # train the random forest classifier with depth\n",
    "    model = RandomForestClassifier(n_estimators=100,max_depth=k)\n",
    "    model.fit(train_data, train_labels)\n",
    " \n",
    "    # evaluation of model\n",
    "    score = model.score(validation_data, validation_labels)\n",
    "    #print(\"k=%d, accuracy=%.2f%%\" % (k, score * 100))\n",
    "    forest_accuracies.append(score)\n",
    " \n",
    "# highest accuracy\n",
    "i = int(np.argmax(forest_accuracies))\n",
    "print(\"k=%d achieved highest accuracy of %.2f%% on validation data\" % (depth_val[i],\n",
    "forest_accuracies[i] * 100))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Gaussian Classifier\n",
    "clf=RandomForestClassifier(n_estimators=100,max_depth=depth_val[i])\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "clf.fit(train_data,train_labels)\n",
    "\n",
    "random_forest_predictions=clf.predict(test_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classification report for each digit\n",
    "print(\"Random Forest Score\")\n",
    "print(classification_report(test_labels, random_forest_predictions))\n",
    "print(\"Accuracy:\",metrics.accuracy_score(test_labels, random_forest_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how many 9's did I find\n",
    "est= np.round(sum(x == 9 for x in random_forest_predictions)*.88,0)\n",
    "print(\"correct predictions: {}\".format(sum(x == 9 for x in random_forest_predictions)*.88))\n",
    "print(\"actual #: {}\".format(sum(x == 9 for x in test_labels)))\n",
    "\n",
    "print(\"about \"+format(est)+\" nines!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
